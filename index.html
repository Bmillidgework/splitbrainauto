<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Splitbrainauto by richzhang</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Splitbrainauto</h1>
      <h2 class="project-tagline">Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction</h2>
      <a href="https://github.com/richzhang/splitbrainauto" class="btn">View on GitHub</a>
      <a href="https://github.com/richzhang/splitbrainauto/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/richzhang/splitbrainauto/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h2>
<a id="split-brain-autoencoders-unsupervised-learning-by-cross-channel-prediction" class="anchor" href="#split-brain-autoencoders-unsupervised-learning-by-cross-channel-prediction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction</h2>

<p><a href="https://richzhang.github.io/">Richard Zhang</a>, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, <a href="http://www.eecs.berkeley.edu/%7Eefros/">Alexei A. Efros</a>. In ArXiv, 2016.</p>

<p><img src="http://richzhang.github.io/index_files/cvpr2017_splitbrain.png" height="180"></p>

<h3>
<a id="overview" class="anchor" href="#overview" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Overview</h3>

<p>This repository contains a test time demonstration using a pre-trained Split-Brain Autoencoder network. The network is a feature extractor using the AlexNet architecture, trained in an unsupervised manner.</p>

<h3>
<a id="clone-this-repository" class="anchor" href="#clone-this-repository" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Clone this repository</h3>

<p>Clone the master branch of the respository using <code>git clone -b master --single-branch https://github.com/richzhang/splitbrainauto.git</code></p>

<h3>
<a id="dependencies" class="anchor" href="#dependencies" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Dependencies</h3>

<p>This code requires a working installation of <a href="http://caffe.berkeleyvision.org/">Caffe</a>. For guidelines and help with installation of Caffe, consult the <a href="http://caffe.berkeleyvision.org/">installation guide</a> and <a href="https://groups.google.com/forum/#!forum/caffe-users">Caffe users group</a>.</p>

<h3>
<a id="test-time-usage" class="anchor" href="#test-time-usage" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Test-Time Usage</h3>

<p><strong>(1)</strong> Run <code>./train/fetch_models.sh</code>. This will load model <code>model_splitbrainauto_clcl.caffemodel</code> into the <code>models</code> directory.</p>

<p><strong>(2)</strong> To extract features, you can (a) use the main branch of Caffe and do color conversion outside of the network or (b) download and install a modified Caffe and not worry about color conversion.</p>

<p><strong>(a)</strong> <strong>Color conversion outside of prototxt</strong> To extract features with the main branch of <a href="http://caffe.berkeleyvision.org/">Caffe</a>: <br>
<strong>(i)</strong> Load the weights <code>model_splitbrainauto_clcl.caffemodel</code> with model definition file <code>deploy_lab.prototxt</code> in the <code>models</code> directory. The input is blob <code>data_lab</code>, which is an <strong><em>image in Lab colorspace</em></strong>. You will have to do the Lab color conversion pre-processing outside of the network.</p>

<p><strong>(b)</strong> <strong>Color conversion in prototxt</strong> You can also extract features with in-prototxt color version with a modified Caffe. <br>
<strong>(i)</strong> Run <code>./train/fetch_caffe.sh</code>. This will load a modified Caffe into directory <code>./caffe-colorization</code>. <br>
<strong>(ii)</strong> Install the modified Caffe. For guidelines and help with installation of Caffe, consult the <a href="http://caffe.berkeleyvision.org/">installation guide</a> and <a href="https://groups.google.com/forum/#!forum/caffe-users">Caffe users group</a>. <br>
<strong>(iii)</strong> Load the weights <code>model_splitbrainauto_clcl.caffemodel</code> with model definition file <code>deploy.prototxt</code> in the <code>models</code> directory. The input is blob <code>data</code>, which is a <strong><em>non mean-centered BGR image</em></strong>.</p>

<h3>
<a id="citation" class="anchor" href="#citation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Citation</h3>

<p>If you find this model useful for your resesarch, please use this <a href="http://richzhang.github.io/index_files/bibtex_arxiv2016_splitbrain.txt">bibtex</a> to cite.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/richzhang/splitbrainauto">Splitbrainauto</a> is maintained by <a href="https://github.com/richzhang">richzhang</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
